---
title: "tets"
output: html_document
date: '2025-01-31'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Projet DevOps Â« from scratch Â»

## Introduction
Ce projet vise Ã  appliquer un workflow DevOps complet, de la crÃ©ation dâ€™une application simple jusqu'Ã  sa mise en production automatisÃ©e sur *Kubernetes* avec *GitOps*. Il inclut Ã©galement les bonnes pratiques en matiÃ¨re de qualitÃ©, monitoring et sÃ©curitÃ©.

## ğŸ“Œ Objectif
Le projet est organisÃ© en **2 parties** :

-	**La base** : dans un premier temps, le but sera de dÃ©velopper et automatiser le dÃ©ploiement dâ€™une application web minimaliste en suivant un workflow DevOps standard.
Lâ€™application, dÃ©veloppÃ©e en Python avec *Flask*, sera contenue dans un container *Docker*, puis dÃ©ployÃ©e sur un cluster *Kubernetes* via *MiniKube*, et gÃ©rÃ©e avec *Helm* et *ArgoCD*.

-	**Pour aller plus loin** : dans un second temps, le but sera d'amÃ©liorer la qualitÃ©, la sÃ©curitÃ© et lâ€™observabilitÃ© de lâ€™application en intÃ©grant des tests unitaires et dâ€™intÃ©gration avec *Pytest*, ainsi quâ€™un systÃ¨me de monitoring et de logs basÃ© sur *Prometheus*.

## ğŸ›  Stack technologique
- **Langage & Framework** : Python, Flask
- **Containerisation & Orchestration** : Docker, Kubernetes, Minikube
- **DÃ©ploiement & Automatisation** : Argo CD, Helm, Git
- **QualitÃ© du code** : Pytest
- **Monitoring & Logs** : Prometheus

## ğŸ“– Concepts abordÃ©s
- **CI/CD** : IntÃ©gration et dÃ©ploiement continus
- **GitOps** : Gestion des dÃ©ploiements via Git
- **Infrastructure as Code (IaC)** : DÃ©finition des infrastructures sous forme de code
- **Cloud-native** : Containerisation et microservices
- **Tests** : Unitaires et dâ€™intÃ©gration
- **Logs & Monitoring**

---

# ğŸ— Base : DÃ©ploiement dâ€™une application Flask sur Kubernetes

## ğŸ“Œ Objectifs
1. **DÃ©veloppement de lâ€™application** : crÃ©ation dâ€™une API Flask simple avec un  endpoint : GET / qui retourne le message Â« Hello from Flask in Kubernetes ! Â».
2. **Containerisation avec Docker** : packaging de lâ€™application sous forme dâ€™image Docker pour garantir la portabilitÃ© et la reproductibilitÃ©.
3. **DÃ©ploiement statique sur Kubernetes** : crÃ©ation et gestion des ressources Kubernetes (deployment, service, namespace) avec des manifests YAML statiques.
4. **DÃ©ploiement dynamique avec Helm** : transformation des manifests statiques en templates Helm, pemettant un dÃ©ploiement flexible et Ã©volutif.
5. **Automatisation avec Argo CD** : mise en place dâ€™une approche GitOps avec Argo CD pour surveiller un repo Git et dÃ©ployer automatiquement les changements sur le cluster Kubernetes.

## 1ï¸âƒ£ DÃ©veloppement de lâ€™application (API Flask)

### Structure du projet

```bash
flask-k8s-argo/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ main.py       # Code de l'API Flask
â”‚   â”œâ”€â”€ __init__.py   # Pour que Python considÃ¨re le dossier /app comme un module
â”‚â”€â”€ requirements.txt  # DÃ©pendances (Flask)
â”‚â”€â”€ Dockerfile        # Fichier pour Docker
â”‚â”€â”€ .gitignore
â”‚â”€â”€ .git
```
On commence par crÃ©er le rÃ©pertoire *flask-k8s-argo* et on passe dedans. On crÃ©e aussi les diffÃ©rents fichiers nÃ©cessaires :

```bash
mkdir flask-k8s-argo && cd flask-k8s-argo
mkdir app
touch app/main.py
touch app/__init__.py
touch requirements.txt
touch Dockerfile
touch .gitignore
```

Pour commiter sur Github, il faut encore initialiser un repo git (nÃ©cessaire aussi plus tard pour ArgoCD)

```bash
git init
```

Ensuite, on peut Ã©crire le code de l'application.

### Code Flask (`app/main.py`)

```python
from flask import Flask, jsonify

app = Flask(__name__)

@app.route('/')
def home():
    return jsonify(message="Hello from Flask in Kubernetes!")

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

Facultativement, on peut aussi spÃ©cifier le contenu du fichier *__init__.py* :

```python
# app/__init__.py
from flask import Flask

app = Flask(__name__)

from app import main  # Import du fichier main.py

```

### Installation des dÃ©pendances

Les dÃ©pendances requises sont listÃ©es dans le fichier *requirements.txt*. Actuellement, nous n'avons besoin que de Flask:

```bash
echo flask > requirements.txt
```
Ensuite, on peut installer les dÃ©pendances requises (Flask)

```bash
pip install -r requirements.txt
```

Si Ã§a ne marche pas, par exemple parce que *pip* n'est pas dans le *PATH*, on peut aussi installer Flask via Python :

```bash
python3 -m pip install -user flask
```

### Test en local

A ce stade, on peut dÃ©jÃ  vÃ©rifier que l'application fonctionne :

```bash
python3 app/main.py
```
Le message suivant devrait apparaÃ®te : "*Running on http://127.0.0.1:5000*". On peut soit se rendre Ã  cette URL dans un browser, ou simplement utiliser *curl* :

```bash
curl http://127.0.0.1:5000
```
Le message "*Hello from Flask in Kubernetes!*" devrait s'afficher.

---

## 2ï¸âƒ£ Containerisation avec Docker

### Dockerfile

Maintenant qu'on sait que l'application fonctionne, on peut la containeriser. On commence par crÃ©er le Dockerfile :

```dockerfile
# Utiliser une image Python lÃ©gÃ¨re
FROM python:3.9-slim

# DÃ©finir le rÃ©pertoire de travail
WORKDIR /app

# Copier les fichiers nÃ©cessaires
COPY requirements.txt ./
COPY app ./app

# Installer Flask
RUN pip install --no-cache-dir -r requirements.txt

# Exposer le port 5000 sur lequel lâ€™application Ã©coutera
EXPOSE 5000

# Lancer l'application
CMD ["python3", "app/main.py"]
```

### Build & run

Maintenant, ce Dockerfile peut Ãªtre utilisÃ© pour crÃ©er une image Docker qu'on appellera *flask-app* :

```bash
docker build -t flask-app .
```
Les images existantes sont visibles avec la commande suivante :

```bash
docker images
```
Finalement, on peut lancer le container :

```bash
docker run -p 5000:5000 flask-app
```

On devrait Ã  nouveau avoir le message "*Hello from Flask in Kubernetes!*".

---

## 3ï¸âƒ£ DÃ©ploiement statique sur Kubernetes avec Minikube

### Installation & dÃ©marrage

Maintenant qu'on a un container Docker qui fonctionne, on peut le dÃ©ployer dans un cluster Kubernetes. On peut utiliser GKE (Google Kubernetes Engine, payant et accessible depuis l'extÃ©rieur) ou Minikube (gratuit, local). On utilisera ici Minikube.

```bash
brew install minikube
minikube version
```
Si l'installation s'est bien passÃ©e, on peut dÃ©marrer un cluster localement :

```bash
minikube start
```
On vÃ©rifie l'Ã©tat du cluster:

```bash
kubectl get nodes
```
Si *Status=Ready*, le cluster est opÃ©rationnel. On peut crÃ©er un namespace pour l'application. Ceci permet de la sÃ©parer d'autres applications Ã©ventuelles, et donc de bien gÃ©rer les ressources Kubernetes.

### CrÃ©ation du namespace Kubernetes

```bash
kubectl create namespace flask-app
kubectl get namespaces
```
Le namespace *flask-app* devrait apparaÃ®tre dans la liste. Les namespaces suivants sont crÃ©Ã©s automatiquement par Kubernetes :

-	Default : namespace par dÃ©faut si on ne prÃ©cise rien au moment du dÃ©ploiement. Toutes les ressources sans namespace explicite iront ici
-	Kube-node-lease : gÃ¨re la communication entre les nÅ“uds du cluster pour savoir sâ€™ils sont actifs
-	Kube-public : contient des ressources accessibles publiquement
-	Kube-system : namespace oÃ¹ tournent les services de k8s (DNS, scheduluer, API server, etcâ€¦)

Maintenant que Minikube tourne et quâ€™on a un namespace, on peut passer au dÃ©ploiement.

### Manifests YAML (`manifests/`)

Pour le dÃ©ploiement, il nous faut deux manifests YAML :

-	**Deployment** : gÃ¨re la crÃ©ation et la mise Ã  jour du container Flask
-	**Service** : expose lâ€™application pour quâ€™elle soit accessible

On place ces manifests dans un dossier *manifests*. La stucture du projet mis Ã  jour est la suivante :

```bash
flask-k8s-argo/
â”‚â”€â”€ app/ 
	â”‚â”€â”€ main.py
	â”‚â”€â”€ __init__.py
â”‚â”€â”€ manifests/ 
	â”‚â”€â”€ deployment.yaml
	â”‚â”€â”€ service.yaml
â”‚â”€â”€ requirements.txt 
â”‚â”€â”€ Dockerfile 
â”‚â”€â”€ .gitignore
â”‚â”€â”€ .git
```

On peut donc crÃ©er le dossier, passer dedans et crÃ©er les manifests : 

```bash
mkdir manifests && cd manifests
touch deployment.yaml service.yaml
```

Le contenu des manifests est le suivant :

#### `deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flask-app
  namespace: flask-app
  labels:
    app: flask-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: flask-app
  template:
    metadata:
      labels:
        app: flask-app
    spec:
      containers:
        - name: flask-app
          image: flask-app
          imagePullPolicy: Never
          ports:
            - containerPort: 5000
```

Le paramÃ¨tre *imagePullPolicy: Never* force Kubernetes Ã  utiliser l'image locale.

#### `service.yaml`

```yaml
apiVersion: v1
kind: Service
metadata:
  name: flask-service
  namespace: flask-app
spec:
  selector:
    app: flask-app
  type: NodePort
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
      nodePort: 30007
```

On dÃ©finit ici un service de type NodePort en dur (normalement Kubernetes assigne automatiquement un port entre 30'000 et 32'767). Un NodePort expose un port spÃ©cifique sur tous les noeuds du cluster, ce qui permet un accÃ¨s externe Ã  une application.

Un noeud est une machine (physique ou virtuelle) qui exÃ©cute les applications Kubernetes.
Un Service NodePort ouvre un port sur tous les *workers nodes* du cluster pour permettre un accÃ¨s externe.
Dans Minikube, tout est sur une seule machine, donc Ã§a fonctionne localement.

Il faut noter que NodePort est pratique pour tester localement, mais pas recommandÃ© en production. En production, on utiliserait plutÃ´t des *ingress controllers* ou *LoadBalancers*.

Une fois les manifests crÃ©Ã©s, on peut les appliquer dans Kubernetes.

### Application des manifests

ConcrÃ¨tement, Kubernetes va lire ces manifests et crÃ©er les ressources correspondantes.

```bash
kubectl apply -f manifests/deployment.yaml
kubectl apply -f manifests/service.yaml
```
Kubernetes crÃ©e donc un dÃ©ploiement qui gÃ¨re le container Flask, et un service qui permet d'y accÃ©der. On vÃ©rifie que tout fonctionne correctement :

```bash
kubectl get pods -n flask-app
kubectl get services -n flask-app
```

On vÃ©rifie finalement que l'application tourne bien dans Kubernetes :

```bash
Kubectl get services -n flask-app
```

Le rÃ©sultat de cette commande devrait ressembler Ã  ceci :

| NAME          | TYPE      | CLUSTER-IP       | EXTERNAL-IP | PORT(S)       | AGE   |
|--------------|----------|------------------|-------------|--------------|------|
| flask-service | NodePort | 10.111.255.215   | <none>      | 80:30007/TCP | 2m47s |

L'adresse IP du cluster, *10.111.255.215*, n'est accessible que depuis l'intÃ©rieur du cluster. *Port(s)=80:300007/TCP* indique que le port 30007 du noeud (le NodePort accessible depuis l'extÃ©rieur) est redirigÃ© vers le port 80 du service, qui est lui-mÃªme redirigÃ© vers le port 5000 de l'application Flask.

### AccÃ¨s Ã  l'application

A ce stade, il y a deux maniÃ¨re d'accÃ©der Ã  l'application :

1. La mÃ©thode *port-forward* de kubectl permet de rediriger temporairement un port local vers l'application :

```bash
kubectl port-forward -n flask-app pod/$(kubectl get pod -n flask-app -o jsonpath='{.items[0].metadata.name}') 5000:5000
```
L'application devrait Ãªtre accessible Ã  l'adresse *http://127.0.0.1:5000*.

2. La mÃ©thode *service* de Minikube permet d'exposer directement un service sur localhost :

```bash
minikube service flask-service -n flask-app --url
```

Cette commande renvoie une URL temporaire, aussi utilisable dans un browser ou via *curl*.

Actuellement, l'application tourne bien dans Kubernetes avec des manifests YAML statiques. 

---

## 4ï¸âƒ£ DÃ©ploiement dynamique avec Helm

Le "problÃ¨me" des manifests statiques est que si on veut modifier des valeurs comme le nombre de *replicas*, l'image Docker, le NodePort, etc..., il faudrait aller modifier ces fichiers manuellement Ã  chaque changement.

*Helm* permet de transformer ces fichiers YAML en **templates**, ce qui permet une configuration dynamique et non plus statique. Cela se fait grÃ¢ce au fichier *values.yaml*.

### Installation de Helm

*Helm* peut Ãªtre installÃ© avec la commande suivante (sur Mac) :

```bash
brew install helm
helm version
```

### Structure du Chart Helm

Une fois installÃ©, la commande suivante crÃ©e un **chart Helm** dans le rÃ©pertoire du projet (nommÃ© ici *flask-chart*) :

```bash
helm create flask-chart 
```

Des dossiers et fichiers sont automatiquement crÃ©Ã©s, et la nouvelle structure du projet est la suivante :

```bash
flask-k8s-argo/
â”‚â”€â”€ app/ 
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ __init__.py
â”‚â”€â”€ flask-chart/              # Dossier du chart Helm
â”‚   â”œâ”€â”€ charts/               # Sous-charts Helm (non utilisÃ© ici)
â”‚   â”œâ”€â”€ templates/            # Contient les templates YAML pour Kubernetes
â”‚   â”‚   â”œâ”€â”€ deployment.yaml   # Template pour le Deployment
â”‚   â”‚   â”œâ”€â”€ service.yaml      # Template pour le Service
â”‚   â”‚   â”œâ”€â”€ _helpers.tpl      # Fonctions rÃ©utilisables pour Helm
â”‚   â”‚   â”œâ”€â”€ NOTES.txt         # Message affichÃ© aprÃ¨s installation du chart
â”‚   â”‚   â”œâ”€â”€ hpa.yaml          # Pour le scaling automatique (non utilisÃ© ici)
â”‚   â”‚   â”œâ”€â”€ ingress.yaml      # Pour exposer via un ingress controller (optionnel)
â”‚   â”œâ”€â”€ values.yaml           # Contient les variables dynamiques
â”‚   â”œâ”€â”€ Chart.yaml            # MÃ©tadonnÃ©es du Chart (nom, version, description)
â”‚   â”œâ”€â”€ .helmignore           # Fichiers Ã  ignorer (comme .gitignore)
â”‚â”€â”€ manifests/                # Ce dossier deviendra obsolÃ¨te avec Helm)
â”‚   â”œâ”€â”€ deployment.yaml       # (sera remplacÃ© par Helm)
â”‚   â”œâ”€â”€ service.yaml          # (sera remplacÃ© par Helm)
â”‚â”€â”€ requirements.txt	
â”‚â”€â”€ Dockerfile		
â”‚â”€â”€ .gitignore			
â”‚â”€â”€ .git

```

Le fichier *values.yaml* contiendra les variables dynamiques (comme le nom du container, les *replicas*, l'image Docker, etc...). Ces fichiers sont dÃ©jÃ  remplis avec des explications quant Ã  leur utilisation.

Il faut modifier les fichiers suivants :

#### `Chart.yaml`

```yaml
apiVersion: v2
name: flask-chart
description: A Helm chart for deploying a Flask app on Kubernetes

type: application

# Version du chart Helm
version: 0.1.0

# Version de l'application
appVersion: "1.0.0"
```

#### `values.yaml`

```yaml
replicaCount: 1

image:
  repository: flask-app
  tag: latest
  pullPolicy: Never

serviceAccount: create: false

ingress:
  enabled: false

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 80

service:
  type: NodePort
  port: 80
  targetPort: 5000
  nodePort: 30007

resources: {}

nodeSelector: {}

tolerations: []

affinity: {}
```

#### `templates/deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-app
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Release.Name }}-app
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ .Release.Name }}-app
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}-app
    spec:
      containers:
        - name: flask-app
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - containerPort: {{ .Values.service.targetPort }}
```

#### `templates/service.yaml`

```yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-service
  namespace: {{ .Release.Namespace }}
spec:
  selector:
    app: {{ .Release.Name }}-app
  type: {{ .Values.service.type }}
  ports:
    - protocol: TCP
      port: {{ .Values.service.port }}
      targetPort: {{ .Values.service.targetPort }}
      nodePort: {{ .Values.service.nodePort }}
```

### Installation du Chart Helm

A ce stade, l'application est prÃªte Ã  Ãªtre redÃ©ployÃ©e avec *Helm* :

```bash
helm install flask-app ./flask-chart --namespace flask-app
helm list -n flask-app
```

Finalement, l'URL d'accÃ¨s Ã  l'application peut Ãªtre rÃ©cupÃ©rÃ©e avec la commande suivante :

```bash
minikube service flask-app-service -n flask-app â€“url
```

---

## 5ï¸âƒ£ Automatisation avec Argo CD

Actuellement, on a un dÃ©ploiement dynamique avec Helm, mais lâ€™application est toujours dÃ©ployÃ©e manuellement avec la commande *helm install*.
Lâ€™objectif est maintenant dâ€™automatiser enitÃ¨rement les dÃ©ploiements en suivant une approche GitOps grÃ¢ce Ã  Argo CD. L'idÃ©e est qu'Argo CD automatise le dÃ©ploiement de l'application en se basant sur un repo Git comme unique source de vÃ©ritÃ© ; il assure que ce qui est dÃ©ployÃ© correspond toujours Ã  l'Ã©tat dÃ©fini dans Git.

C'est donc un bon moment pour crÃ©er un repo Git (si pas dÃ©jÃ  le cas). 

### Installation d'Argo CD

Argo CD peut Ãªtre installÃ© directement dans Kubernetes via *kubectl* :

```bash
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
```

La commande suivante permet de contrÃ´ler que l'installation s'est dÃ©roulÃ©e correctement :

```bash
kubectl get pods -n argocd
```
Les pods doivent Ãªtre en *Running* avec *Ready 1/1* (Ã§a peut prendre quelques minutes).
---

# ğŸ” Approfondissement : QualitÃ©, SÃ©curitÃ© & ObservabilitÃ©
## Objectifs
- **Tests** : IntÃ©gration de Pytest
- **SÃ©curitÃ©** : Scan des vulnÃ©rabilitÃ©s Docker
- **Monitoring & Logs** : IntÃ©gration avec Prometheus

## ğŸ›  Prochaines Ã©tapes
Ã€ complÃ©ter...

---

