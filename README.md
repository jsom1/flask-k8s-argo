---
title: "tets"
output: html_document
date: '2025-01-31'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Projet DevOps ¬´ from scratch ¬ª

## Introduction
Ce projet vise √† appliquer un workflow DevOps complet, de la cr√©ation d‚Äôune application simple jusqu'√† sa mise en production automatis√©e sur *Kubernetes* avec *GitOps*. Il inclut √©galement les bonnes pratiques en mati√®re de qualit√©, monitoring et s√©curit√©.

## üìå Objectif
Le projet est organis√© en **2 parties** :

-	**La base** : dans un premier temps, le but sera de d√©velopper et automatiser le d√©ploiement d‚Äôune application web minimaliste en suivant un workflow DevOps standard.
L‚Äôapplication, d√©velopp√©e en Python avec *Flask*, sera contenue dans un container *Docker*, puis d√©ploy√©e sur un cluster *Kubernetes* via *MiniKube*, et g√©r√©e avec *Helm* et *ArgoCD*.

-	**Pour aller plus loin** : dans un second temps, le but sera d'am√©liorer la qualit√©, la s√©curit√© et l‚Äôobservabilit√© de l‚Äôapplication en int√©grant des tests unitaires et d‚Äôint√©gration avec *Pytest*, ainsi qu‚Äôun syst√®me de monitoring et de logs bas√© sur *Prometheus*.

## üõ† Stack technologique
- **Langage & Framework** : Python, Flask
- **Containerisation & Orchestration** : Docker, Kubernetes, Minikube
- **D√©ploiement & Automatisation** : Argo CD, Helm, Git
- **Qualit√© du code** : Pytest
- **Monitoring & Logs** : Prometheus

## üìñ Concepts abord√©s
- **CI/CD** : Int√©gration et d√©ploiement continus
- **GitOps** : Gestion des d√©ploiements via Git
- **Infrastructure as Code (IaC)** : D√©finition des infrastructures sous forme de code
- **Cloud-native** : Containerisation et microservices
- **Tests** : Unitaires et d‚Äôint√©gration
- **Logs & Monitoring**

---

# üèó Base : D√©ploiement d‚Äôune application Flask sur Kubernetes

## üìå Objectifs
1. **D√©veloppement de l‚Äôapplication** : cr√©ation d‚Äôune API Flask simple avec un  endpoint : GET / qui retourne le message ¬´ Hello from Flask in Kubernetes ! ¬ª.
2. **Containerisation avec Docker** : packaging de l‚Äôapplication sous forme d‚Äôimage Docker pour garantir la portabilit√© et la reproductibilit√©.
3. **D√©ploiement statique sur Kubernetes** : cr√©ation et gestion des ressources Kubernetes (deployment, service, namespace) avec des manifests YAML statiques.
4. **D√©ploiement dynamique avec Helm** : transformation des manifests statiques en templates Helm, pemettant un d√©ploiement flexible et √©volutif.
5. **Automatisation avec Argo CD** : mise en place d‚Äôune approche GitOps avec Argo CD pour surveiller un repo Git et d√©ployer automatiquement les changements sur le cluster Kubernetes.

## 1Ô∏è‚É£ D√©veloppement de l‚Äôapplication (API Flask)

### Structure du projet

```bash
flask-k8s-argo/
‚îÇ‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py       # Code de l'API Flask
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py   # Pour que Python consid√®re le dossier /app comme un module
‚îÇ‚îÄ‚îÄ requirements.txt  # D√©pendances (Flask)
‚îÇ‚îÄ‚îÄ Dockerfile        # Fichier pour Docker
‚îÇ‚îÄ‚îÄ .gitignore
‚îÇ‚îÄ‚îÄ .git
```
On commence par cr√©er le r√©pertoire *flask-k8s-argo* et on passe dedans. On cr√©e aussi les diff√©rents fichiers n√©cessaires :

```bash
mkdir flask-k8s-argo && cd flask-k8s-argo
mkdir app
touch app/main.py
touch app/__init__.py
touch requirements.txt
touch Dockerfile
touch .gitignore
```

Pour commiter sur Github, il faut encore initialiser un repo git (n√©cessaire aussi plus tard pour ArgoCD)

```bash
git init
```

Ensuite, on peut √©crire le code de l'application.

### Code Flask (`app/main.py`)

```python
from flask import Flask, jsonify

app = Flask(__name__)

@app.route('/')
def home():
    return jsonify(message="Hello from Flask in Kubernetes!")

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

Facultativement, on peut aussi sp√©cifier le contenu du fichier *__init__.py* :

```python
# app/__init__.py
from flask import Flask

app = Flask(__name__)

from app import main  # Import du fichier main.py

```

### Installation des d√©pendances

Les d√©pendances requises sont list√©es dans le fichier *requirements.txt*. Actuellement, nous n'avons besoin que de Flask:

```bash
echo flask > requirements.txt
```
Ensuite, on peut installer les d√©pendances requises (Flask)

```bash
pip install -r requirements.txt
```

Si √ßa ne marche pas, par exemple parce que *pip* n'est pas dans le *PATH*, on peut aussi installer Flask via Python :

```bash
python3 -m pip install -user flask
```

### Test en local

A ce stade, on peut d√©j√† v√©rifier que l'application fonctionne :

```bash
python3 app/main.py
```
Le message suivant devrait appara√Æte : "*Running on http://127.0.0.1:5000*". On peut soit se rendre √† cette URL dans un browser, ou simplement utiliser *curl* :

```bash
curl http://127.0.0.1:5000
```
Le message "*Hello from Flask in Kubernetes!*" devrait s'afficher.

---

## 2Ô∏è‚É£ Containerisation avec Docker

### Dockerfile

Maintenant qu'on sait que l'application fonctionne, on peut la containeriser. On commence par cr√©er le Dockerfile :

```dockerfile
# Utiliser une image Python l√©g√®re
FROM python:3.9-slim

# D√©finir le r√©pertoire de travail
WORKDIR /app

# Copier les fichiers n√©cessaires
COPY requirements.txt ./
COPY app ./app

# Installer Flask
RUN pip install --no-cache-dir -r requirements.txt

# Exposer le port 5000 sur lequel l‚Äôapplication √©coutera
EXPOSE 5000

# Lancer l'application
CMD ["python3", "app/main.py"]
```

### Build & run

Maintenant, ce Dockerfile peut √™tre utilis√© pour cr√©er une image Docker qu'on appellera *flask-app* :

```bash
docker build -t flask-app .
```
Les images existantes sont visibles avec la commande suivante :

```bash
docker images
```
Finalement, on peut lancer le container :

```bash
docker run -p 5000:5000 flask-app
```

On devrait √† nouveau avoir le message "*Hello from Flask in Kubernetes!*".

---

## 3Ô∏è‚É£ D√©ploiement statique sur Kubernetes avec Minikube

### Installation & d√©marrage

Maintenant qu'on a un container Docker qui fonctionne, on peut le d√©ployer dans un cluster Kubernetes. On peut utiliser GKE (Google Kubernetes Engine, payant et accessible depuis l'ext√©rieur) ou Minikube (gratuit, local). On utilisera ici Minikube.

```bash
brew install minikube
minikube version
```
Si l'installation s'est bien pass√©e, on peut d√©marrer un cluster localement :

```bash
minikube start
```
On v√©rifie l'√©tat du cluster:

```bash
kubectl get nodes
```
Si *Status=Ready*, le cluster est op√©rationnel. On peut cr√©er un namespace pour l'application. Ceci permet de la s√©parer d'autres applications √©ventuelles, et donc de bien g√©rer les ressources Kubernetes.

### Cr√©ation du namespace Kubernetes

```bash
kubectl create namespace flask-app
kubectl get namespaces
```
Le namespace *flask-app* devrait appara√Ætre dans la liste. Les namespaces suivants sont cr√©√©s automatiquement par Kubernetes :

-	Default : namespace par d√©faut si on ne pr√©cise rien au moment du d√©ploiement. Toutes les ressources sans namespace explicite iront ici
-	Kube-node-lease : g√®re la communication entre les n≈ìuds du cluster pour savoir s‚Äôils sont actifs
-	Kube-public : contient des ressources accessibles publiquement
-	Kube-system : namespace o√π tournent les services de k8s (DNS, scheduluer, API server, etc‚Ä¶)

Maintenant que Minikube tourne et qu‚Äôon a un namespace, on peut passer au d√©ploiement.

### Manifests YAML (`manifests/`)

Pour le d√©ploiement, il nous faut deux manifests YAML :

-	**Deployment** : g√®re la cr√©ation et la mise √† jour du container Flask
-	**Service** : expose l‚Äôapplication pour qu‚Äôelle soit accessible

On place ces manifests dans un dossier *manifests*. La stucture du projet mis √† jour est la suivante :

```bash
flask-k8s-argo/
‚îÇ‚îÄ‚îÄ app/ 
	‚îÇ‚îÄ‚îÄ main.py
	‚îÇ‚îÄ‚îÄ __init__.py
‚îÇ‚îÄ‚îÄ manifests/ 
	‚îÇ‚îÄ‚îÄ deployment.yaml
	‚îÇ‚îÄ‚îÄ service.yaml
‚îÇ‚îÄ‚îÄ requirements.txt 
‚îÇ‚îÄ‚îÄ Dockerfile 
‚îÇ‚îÄ‚îÄ .gitignore
‚îÇ‚îÄ‚îÄ .git
```

On peut donc cr√©er le dossier, passer dedans et cr√©er les manifests : 

```bash
mkdir manifests && cd manifests
touch deployment.yaml service.yaml
```

Le contenu des manifests est le suivant :

#### `deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flask-app
  namespace: flask-app
  labels:
    app: flask-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: flask-app
  template:
    metadata:
      labels:
        app: flask-app
    spec:
      containers:
        - name: flask-app
          image: flask-app
          imagePullPolicy: Never
          ports:
            - containerPort: 5000
```

Le param√®tre *imagePullPolicy: Never* force Kubernetes √† utiliser l'image locale.

#### `service.yaml`

```yaml
apiVersion: v1
kind: Service
metadata:
  name: flask-service
  namespace: flask-app
spec:
  selector:
    app: flask-app
  type: NodePort
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
      nodePort: 30007
```

On d√©finit ici un service de type NodePort en dur (normalement Kubernetes assigne automatiquement un port entre 30'000 et 32'767). Un NodePort expose un port sp√©cifique sur tous les noeuds du cluster, ce qui permet un acc√®s externe √† une application.

Un noeud est une machine (physique ou virtuelle) qui ex√©cute les applications Kubernetes.
Un Service NodePort ouvre un port sur tous les *workers nodes* du cluster pour permettre un acc√®s externe.
Dans Minikube, tout est sur une seule machine, donc √ßa fonctionne localement.

Il faut noter que NodePort est pratique pour tester localement, mais pas recommand√© en production. En production, on utiliserait plut√¥t des *ingress controllers* ou *LoadBalancers*.

Une fois les manifests cr√©√©s, on peut les appliquer dans Kubernetes.

### Application des manifests

Concr√®tement, Kubernetes va lire ces manifests et cr√©er les ressources correspondantes.

```bash
kubectl apply -f manifests/deployment.yaml
kubectl apply -f manifests/service.yaml
```
Kubernetes cr√©e donc un d√©ploiement qui g√®re le container Flask, et un service qui permet d'y acc√©der. On v√©rifie que tout fonctionne correctement :

```bash
kubectl get pods -n flask-app
kubectl get services -n flask-app
```

On v√©rifie finalement que l'application tourne bien dans Kubernetes :

```bash
Kubectl get services -n flask-app
```

Le r√©sultat de cette commande devrait ressembler √† ceci :

| NAME          | TYPE      | CLUSTER-IP       | EXTERNAL-IP | PORT(S)       | AGE   |
|--------------|----------|------------------|-------------|--------------|------|
| flask-service | NodePort | 10.111.255.215   | <none>      | 80:30007/TCP | 2m47s |

L'adresse IP du cluster, *10.111.255.215*, n'est accessible que depuis l'int√©rieur du cluster. *Port(s)=80:300007/TCP* indique que le port 30007 du noeud (le NodePort accessible depuis l'ext√©rieur) est redirig√© vers le port 80 du service, qui est lui-m√™me redirig√© vers le port 5000 de l'application Flask.

### Acc√®s √† l'application

A ce stade, il y a deux mani√®re d'acc√©der √† l'application :

1. La m√©thode *port-forward* de kubectl permet de rediriger temporairement un port local vers l'application :

```bash
kubectl port-forward -n flask-app pod/$(kubectl get pod -n flask-app -o jsonpath='{.items[0].metadata.name}') 5000:5000
```
L'application devrait √™tre accessible √† l'adresse *http://127.0.0.1:5000*.

2. La m√©thode *service* de Minikube permet d'exposer directement un service sur localhost :

```bash
minikube service flask-service -n flask-app --url
```

Cette commande renvoie une URL temporaire, aussi utilisable dans un browser ou via *curl*.

Actuellement, l'application tourne bien dans Kubernetes avec des manifests YAML statiques. 

---

## 4Ô∏è‚É£ D√©ploiement dynamique avec Helm

Le "probl√®me" des manifests statiques est que si on veut modifier des valeurs comme le nombre de *replicas*, l'image Docker, le NodePort, etc..., il faudrait aller modifier ces fichiers manuellement √† chaque changement.

*Helm* permet de transformer ces fichiers YAML en **templates**, ce qui permet une configuration dynamique et non plus statique. Cela se fait gr√¢ce au fichier *values.yaml*.

### Installation de Helm

*Helm* peut √™tre install√© avec la commande suivante (sur Mac) :

```bash
brew install helm
helm version
```

### Structure du Chart Helm

Une fois install√©, la commande suivante cr√©e un **chart Helm** dans le r√©pertoire du projet (nomm√© ici *flask-chart*) :

```bash
helm create flask-chart 
```

Des dossiers et fichiers sont automatiquement cr√©√©s, et la nouvelle structure du projet est la suivante :

```bash
flask-k8s-argo/
‚îÇ‚îÄ‚îÄ app/ 
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ‚îÄ‚îÄ flask-chart/              # Dossier du chart Helm
‚îÇ   ‚îú‚îÄ‚îÄ charts/               # Sous-charts Helm (non utilis√© ici)
‚îÇ   ‚îú‚îÄ‚îÄ templates/            # Contient les templates YAML pour Kubernetes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml   # Template pour le Deployment
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.yaml      # Template pour le Service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ _helpers.tpl      # Fonctions r√©utilisables pour Helm
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NOTES.txt         # Message affich√© apr√®s installation du chart
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hpa.yaml          # Pour le scaling automatique (non utilis√© ici)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml      # Pour exposer via un ingress controller (optionnel)
‚îÇ   ‚îú‚îÄ‚îÄ values.yaml           # Contient les variables dynamiques
‚îÇ   ‚îú‚îÄ‚îÄ Chart.yaml            # M√©tadonn√©es du Chart (nom, version, description)
‚îÇ   ‚îú‚îÄ‚îÄ .helmignore           # Fichiers √† ignorer (comme .gitignore)
‚îÇ‚îÄ‚îÄ manifests/                # Ce dossier deviendra obsol√®te avec Helm)
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml       # (sera remplac√© par Helm)
‚îÇ   ‚îú‚îÄ‚îÄ service.yaml          # (sera remplac√© par Helm)
‚îÇ‚îÄ‚îÄ requirements.txt	
‚îÇ‚îÄ‚îÄ Dockerfile		
‚îÇ‚îÄ‚îÄ .gitignore			
‚îÇ‚îÄ‚îÄ .git

```

Le fichier *values.yaml* contiendra les variables dynamiques (comme le nom du container, les *replicas*, l'image Docker, etc...). Ces fichiers sont d√©j√† remplis avec des explications quant √† leur utilisation.

Il faut modifier les fichiers suivants :

#### `Chart.yaml`

```yaml
apiVersion: v2
name: flask-chart
description: A Helm chart for deploying a Flask app on Kubernetes

type: application

# Version du chart Helm
version: 0.1.0

# Version de l'application
appVersion: "1.0.0"
```

#### `values.yaml`

```yaml
replicaCount: 1

image:
  repository: flask-app
  tag: latest
  pullPolicy: Never

serviceAccount: create: false

ingress:
  enabled: false

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 80

service:
  type: NodePort
  port: 80
  targetPort: 5000
  nodePort: 30007

resources: {}

nodeSelector: {}

tolerations: []

affinity: {}
```

#### `templates/deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-app
  namespace: {{ .Release.Namespace }}
  labels:
    app: {{ .Release.Name }}-app
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ .Release.Name }}-app
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}-app
    spec:
      containers:
        - name: flask-app
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - containerPort: {{ .Values.service.targetPort }}
```

#### `templates/service.yaml`

```yaml
apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-service
  namespace: {{ .Release.Namespace }}
spec:
  selector:
    app: {{ .Release.Name }}-app
  type: {{ .Values.service.type }}
  ports:
    - protocol: TCP
      port: {{ .Values.service.port }}
      targetPort: {{ .Values.service.targetPort }}
      nodePort: {{ .Values.service.nodePort }}
```

### Installation du Chart Helm

A ce stade, l'application est pr√™te √† √™tre red√©ploy√©e avec *Helm* :

```bash
helm install flask-app ./flask-chart --namespace flask-app
helm list -n flask-app
```

Finalement, l'URL d'acc√®s √† l'application peut √™tre r√©cup√©r√©e avec la commande suivante :

```bash
minikube service flask-app-service -n flask-app ‚Äìurl
```

---

## 5Ô∏è‚É£ Automatisation avec Argo CD

Actuellement, on a un d√©ploiement dynamique avec Helm, mais l‚Äôapplication est toujours d√©ploy√©e manuellement avec la commande *helm install*.
L‚Äôobjectif est maintenant d‚Äôautomatiser enit√®rement les d√©ploiements en suivant une approche GitOps gr√¢ce √† Argo CD. L'id√©e est qu'Argo CD automatise le d√©ploiement de l'application en se basant sur un repo Git comme unique source de v√©rit√© ; il assure que ce qui est d√©ploy√© correspond toujours √† l'√©tat d√©fini dans Git.

C'est donc un bon moment pour cr√©er un repo Git (si pas d√©j√† le cas). 

### Installation d'Argo CD

Argo CD peut √™tre install√© directement dans Kubernetes via *kubectl* :

```bash
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
```

La commande suivante permet de contr√¥ler que l'installation s'est d√©roul√©e correctement :

```bash
kubectl get pods -n argocd
```
Les pods doivent √™tre en *Running* avec *Ready 1/1* (√ßa peut prendre quelques minutes).
---

# üîç Approfondissement : Qualit√©, S√©curit√© & Observabilit√©
## Objectifs
- **Tests** : Int√©gration de Pytest
- **S√©curit√©** : Scan des vuln√©rabilit√©s Docker
- **Monitoring & Logs** : Int√©gration avec Prometheus

## üõ† Prochaines √©tapes
√Ä compl√©ter...

---

